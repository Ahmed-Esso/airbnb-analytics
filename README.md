<div align="center">

# ğŸ  Airbnb Analytics
### European Price Analysis & ML Prediction

[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://share.streamlit.io)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)](https://www.r-project.org)
[![SQL Server](https://img.shields.io/badge/SQL_Server-CC2927?style=for-the-badge&logo=microsoftsqlserver&logoColor=white)](https://www.microsoft.com/sql-server)
[![Power BI](https://img.shields.io/badge/Power_BI-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)](https://powerbi.microsoft.com)

An end-to-end data analytics project analyzing **51,000+ Airbnb listings** across **10 European cities**.  
From web scraping to ML-powered price prediction â€” covering ETL, data warehousing, statistical testing, and interactive dashboards.

**Amsterdam Â· Athens Â· Barcelona Â· Berlin Â· Budapest Â· Lisbon Â· London Â· Paris Â· Rome Â· Vienna**

</div>

---

![Dashboard Preview](dashboard/screenshots/page_1.jpg)

---

## ğŸ“‹ Table of Contents

- [Project Architecture](#-project-architecture)
- [Repository Structure](#-repository-structure)
- [Detailed File Descriptions](#-detailed-file-descriptions)
- [Tech Stack](#-tech-stack)
- [Features](#-features)
- [Quick Start](#-quick-start)
- [Streamlit Cloud Deployment](#-streamlit-cloud-deployment)
- [Dashboard Gallery](#-dashboard-gallery)
- [Star Schema & Database](#-star-schema--database)
- [License](#-license)

---

## ğŸ— Project Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ•· Scraper  â”‚â”€â”€â”€â”€â–¶â”‚  ğŸ§¹ Cleaning &   â”‚â”€â”€â”€â”€â–¶â”‚  ğŸ—ƒ Star Schema     â”‚
â”‚  (Playwright)â”‚     â”‚  Merging (Pandas) â”‚     â”‚  (SQL Server DW)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â–¼                           â–¼                   â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ğŸ“Š Power BI â”‚          â”‚  ğŸ“ˆ R Stats   â”‚    â”‚  ğŸ¤– Streamlit â”‚
                    â”‚  Dashboard   â”‚          â”‚  ANOVA/MANOVA â”‚    â”‚  + CatBoost   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **Pipeline flow:** Scrape raw listings â†’ Clean & merge datasets â†’ Load into star schema â†’ Analyze with SQL, R, and Power BI â†’ Predict prices with CatBoost via Streamlit

---

## ğŸ“ Repository Structure

```
airbnb-analytics/
â”‚
â”œâ”€â”€ ğŸ“‚ app/                          # Streamlit web application
â”‚   â”œâ”€â”€ app.py                       # Main app (dashboard + AI predictor)
â”‚   â”œâ”€â”€ airbnb_model.cbm             # Trained CatBoost model
â”‚   â”œâ”€â”€ airbnb_symbol.svg            # App intro logo
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ airbnb_listings_clean.csv # Final cleaned dataset
â”‚
â”œâ”€â”€ ğŸ“‚ scraper/                      # Web scraping tools
â”‚   â”œâ”€â”€ scraper_cli.py               # Command-line scraper
â”‚   â”œâ”€â”€ scraper_gui.py               # GUI scraper with Tkinter
â”‚   â”œâ”€â”€ logo_base64.txt              # GUI logo (base64 encoded)
â”‚   â””â”€â”€ WEEKEND_SCRAPING_GUIDE.md    # Weekend mode documentation
â”‚
â”œâ”€â”€ ğŸ“‚ cleaning/                     # Data cleaning pipeline
â”‚   â”œâ”€â”€ clean_and_merge.ipynb        # Cleaning notebook
â”‚   â”œâ”€â”€ all_cities.csv               # Source dataset 1 (existing listings)
â”‚   â””â”€â”€ scraped_data.csv             # Source dataset 2 (scraped from Airbnb)
â”‚
â”œâ”€â”€ ğŸ“‚ schema/                       # Database & data warehouse
â”‚   â”œâ”€â”€ star_schema.sql              # Database DDL (tables + bulk insert)
â”‚   â”œâ”€â”€ analysis.sql                 # 9 advanced analytical queries
â”‚   â”œâ”€â”€ hashing.ipynb                # Dimension ID generation notebook
â”‚   â”œâ”€â”€ schema_diagram.png           # Star schema visual diagram
â”‚   â”œâ”€â”€ erd.pdf                      # Entity-Relationship Diagram
â”‚   â”œâ”€â”€ fact_table_output.csv        # Exported fact table
â”‚   â””â”€â”€ final_raw_with_ids.csv       # Full dataset with dimension IDs
â”‚
â”œâ”€â”€ ğŸ“‚ r_statistics/                 # Statistical analysis
â”‚   â””â”€â”€ stat.R                       # ANOVA & MANOVA tests
â”‚
â”œâ”€â”€ ğŸ“‚ dashboard/                    # Power BI dashboard
â”‚   â”œâ”€â”€ airbnb_dashboard.pbix        # Power BI file (4 pages)
â”‚   â””â”€â”€ screenshots/                 # Exported dashboard images
â”‚       â”œâ”€â”€ page_1.jpg               # Overview page
â”‚       â”œâ”€â”€ page_2.jpg               # City comparison page
â”‚       â”œâ”€â”€ page_3.jpg               # Pricing analysis page
â”‚       â””â”€â”€ page_4.jpg               # Host & amenity insights page
â”‚
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .gitattributes                   # Git LFS tracking rules
â”œâ”€â”€ .gitignore                       # Ignored files & folders
â””â”€â”€ README.md                        # This file
```

---

## ğŸ“– Detailed File Descriptions

### ğŸ¤– `app/` â€” Streamlit Web Application

| File | Description |
|------|-------------|
| **`app.py`** | Full-featured Streamlit dashboard (573 lines). Includes an animated intro screen, sidebar with 7 interactive filters (city, room type, price range, guest capacity, rating, superhost, weekend), 3 KPI cards, an interactive Plotly map with click-to-predict, 6 analytical charts (satisfaction gauge, room type pie, price box plot, weekend comparison bar, superhost donut, capacity bar), and an AI Smart Predictor form that uses CatBoost to estimate nightly prices. |
| **`airbnb_model.cbm`** | Trained CatBoost Regressor model. Predicts `log(price)` from features like city, room type, guest capacity, cleanliness rating, distance from center, and weekend flag. The app applies `np.expm1()` to convert predictions back to dollar amounts. |
| **`airbnb_symbol.svg`** | Airbnb logo SVG used in the app's 3-second intro animation (fade-in + scale effect). |
| **`data/airbnb_listings_clean.csv`** | The final cleaned dataset with 51,000+ rows and 30+ columns. Each row is a single Airbnb listing with price, location, amenities, ratings, and derived features. This is the single source of truth for the app. |

### ğŸ•· `scraper/` â€” Web Scraping Tools

| File | Description |
|------|-------------|
| **`scraper_cli.py`** | Command-line Playwright scraper (661 lines). Launches headless Chromium, navigates Airbnb search pages for a given city, collects listing URLs, then visits each listing to extract: price per night, room type, guest capacity, amenities (wifi, kitchen, AC, parking, TV, heating), latitude/longitude, ratings, superhost status, and more. Outputs CSV + JSON files. Handles anti-bot detection with random delays and stealth mode. |
| **`scraper_gui.py`** | Full Tkinter GUI wrapper (1,270 lines) around the scraper engine. Features: mode selection (city search / direct URL / single listing), quick-select buttons for all 10 cities, parallel scraping with `ThreadPoolExecutor`, weekend mode toggle, real-time progress bar, scrollable log window, auto-save per city, and export to CSV. Includes a branded UI with the embedded logo. |
| **`logo_base64.txt`** | Base64-encoded PNG logo used by the GUI scraper. Loaded at runtime to avoid external image dependencies. |
| **`WEEKEND_SCRAPING_GUIDE.md`** | Documentation for the weekend scraping mode â€” explains how to scrape weekend-specific pricing data and merge it with existing datasets using the enrichment pipeline. |

### ğŸ§¹ `cleaning/` â€” Data Cleaning & Merging

| File | Description |
|------|-------------|
| **`clean_and_merge.ipynb`** | Jupyter notebook (27 cells) that runs the full data cleaning pipeline: **(1)** Loads `all_cities.csv` and `scraped_data.csv`, **(2)** normalizes columns (converts cleanliness from 10-scale to 5-scale, renames lat/lng), **(3)** creates binary flags (`room_shared`, `room_private`), **(4)** extracts city from host location and filters to the 10 target cities, **(5)** engineers features: weekend/weekday indicator, amenity booleans (wifi, kitchen, AC, parking, TV, heating), **(6)** merges both datasets via `pd.concat`, **(7)** applies KNN imputation (k=3, distance-weighted) in batches of 100 rows for missing amenities, bedrooms, and beds, **(8)** outputs the final clean CSV. Uses `tqdm` for progress tracking. |
| **`all_cities.csv`** | Source dataset 1 â€” pre-existing Airbnb listing data covering all 10 cities with columns like `realSum`, `room_type`, `person_capacity`, `cleanliness_rating`, `guest_satisfaction_overall`, `dist` (distance to center), `metro_dist`, and attraction/restaurant indices. |
| **`scraped_data.csv`** | Source dataset 2 (254 MB) â€” raw data scraped from Airbnb/Inside Airbnb. Contains listing prices, coordinates, room details, and amenity flags. Merged with dataset 1 to create the comprehensive final dataset. |

### ğŸ—ƒ `schema/` â€” Star Schema & SQL Analytics

| File | Description |
|------|-------------|
| **`star_schema.sql`** | SQL Server DDL script that creates the `Airbnb_DW` data warehouse. Defines **5 dimension tables** (`Dim_Location`, `Dim_Host`, `Dim_Room_Type`, `Dim_Amenities`, `Dim_Day`) and **1 fact table** (`Fact_Listings`) with foreign key constraints. Includes a staging `Raw_Data` table and `BULK INSERT` command to load CSV data. Also contains `INSERT INTO` statements to populate dimensions from the staging table. |
| **`analysis.sql`** | 9 advanced analytical SQL queries (849 lines) that run against the star schema: |
| | **1. ListingScore** â€” Scores each listing against city/room-type benchmarks |
| | **2. SegmentDashboard** â€” Aggregates metrics by city Ã— room-type segments |
| | **3. BestDeals / WorstDeals** â€” Finds underpriced and overpriced listings |
| | **4. AccessibilitySegment** â€” Compares metro-accessible vs center-close listings |
| | **5. AmenityTier** â€” Classifies listings as Basic / Comfort / Full amenity tiers |
| | **6. InsightColumns AllInOne** â€” Combines all analytical columns into one view |
| | **7. FeatureImpactRadar** â€” Measures price premium/discount per feature |
| | **8. GeoDemandHotspots** â€” Geographic grid analysis for high-demand areas |
| | **9. StrategyScoring** â€” Scores weekend + amenity pricing strategies |
| **`hashing.ipynb`** | Jupyter notebook (19 cells) that generates unique dimension IDs using MD5 hashing. For each dimension table, it extracts unique combinations of attributes, hashes them into integer IDs, merges all IDs back to the original dataset, cleans up duplicate columns from the merge, and exports the final dataset with all foreign keys. |
| **`schema_diagram.png`** | Visual diagram of the star schema showing the relationships between the fact table and all 5 dimensions. |
| **`erd.pdf`** | Entity-Relationship Diagram (PDF) documenting the full database design. |
| **`fact_table_output.csv`** | Exported fact table containing listing measures (price, capacity, bedrooms, beds, ratings) linked to dimension IDs. |
| **`final_raw_with_ids.csv`** | Complete dataset (73 MB) with all original columns plus the 5 generated dimension IDs (`location_id`, `host_id`, `room_type_id`, `amenity_id`, `day_id`). Used by R statistics and SQL BULK INSERT. |

### ğŸ“ˆ `r_statistics/` â€” Statistical Analysis

| File | Description |
|------|-------------|
| **`stat.R`** | R script (190 lines) performing two key statistical tests: |
| | **ANOVA** â€” One-way analysis of variance testing whether mean price differs significantly across room types (Entire home, Private room, Shared room). Includes Tukey HSD post-hoc test to identify which pairs differ. Produces boxplots and error bar charts. |
| | **MANOVA** â€” Multivariate analysis testing whether room type simultaneously affects price, guest satisfaction, and cleanliness rating. Uses Wilks' Lambda test statistic. Produces scatter pair plots and grouped bar charts comparing means across all three variables. |
| | Uses `dplyr` for data aggregation (group means, standard errors). All visualizations use Airbnb brand colors (`#FF5A5F`, `#FBB6B8`, `#C81E1E`). |

### ğŸ“Š `dashboard/` â€” Power BI Dashboard

| File | Description |
|------|-------------|
| **`airbnb_dashboard.pbix`** | Power BI dashboard with 4 interactive pages. Connects to the star schema data and provides drill-down visualizations for pricing trends, city comparisons, host performance, and amenity impact analysis. |
| **`screenshots/page_1-4.jpg`** | Exported images of each dashboard page for preview in this README (see [Dashboard Gallery](#-dashboard-gallery) below). |

### ğŸ“„ Root Files

| File | Description |
|------|-------------|
| **`requirements.txt`** | Python dependencies for the Streamlit app: `streamlit`, `pandas`, `plotly`, `numpy`, `catboost`. Placed at the repo root so Streamlit Cloud auto-detects it. |
| **`.gitattributes`** | Git LFS tracking rules â€” all `.csv`, `.cbm`, and `.pbix` files are stored in Git Large File Storage to stay under GitHub's 100 MB per-file limit. |
| **`.gitignore`** | Excludes virtual environments, `__pycache__`, R session files, IDE configs, OS files, backup files, and scraper runtime outputs from version control. |

---

## ğŸ›  Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Scraping** | Python, Playwright, Chromium | Headless browser automation for data collection |
| **Data Cleaning** | Pandas, NumPy, Scikit-learn | Merging, normalization, KNN imputation |
| **Database** | SQL Server | Star schema data warehouse (5 dim + 1 fact) |
| **Statistics** | R, dplyr | ANOVA, MANOVA, Tukey HSD post-hoc tests |
| **Dashboard** | Power BI | 4-page interactive business intelligence dashboard |
| **ML Model** | CatBoost Regressor | Log-price prediction with gradient boosting |
| **Web App** | Streamlit, Plotly | Interactive dashboard + real-time price predictor |
| **Version Control** | Git, Git LFS | Large file storage for CSVs, model, and Power BI |

---

## âœ¨ Features

### Streamlit Web App
| Feature | Details |
|---------|---------|
| ğŸ—º **Interactive Map** | Plotly scatter map of 1,500 sampled listings with color-coded prices. Click any point to trigger an AI price prediction for that location. |
| ğŸ› **7 Sidebar Filters** | City, room type, price range, guest capacity, minimum rating, superhost status, and day type (weekend/weekday). All apply in real-time. |
| ğŸ“Š **3 KPI Cards** | Total listings count, average nightly price, and average guest satisfaction â€” all responsive to active filters. |
| ğŸ“ˆ **6 Charts** | Satisfaction gauge, room type pie chart, price box plot by room type, weekend vs weekday bar chart, superhost donut chart, and price by guest capacity. |
| ğŸ¤– **AI Predictor** | Form-based interface: select city, room type, capacity, cleanliness, distance, and weekend â€” get an instant CatBoost price estimate. |
| ğŸ¬ **Intro Animation** | 3-second branded splash screen with SVG logo fade-in on first load. |

### Data Pipeline
| Stage | Details |
|-------|---------|
| ğŸ•· **Scraping** | Headless Chromium navigates Airbnb, extracts listing data with anti-detection (random delays, stealth mode). Supports batch city scraping and weekend mode. |
| ğŸ§¹ **Cleaning** | Normalizes two heterogeneous datasets, engineers 10+ features, applies batched KNN imputation (k=3, distance-weighted) for missing values. |
| ğŸ—ƒ **Warehousing** | MD5-hashed dimension keys, star schema with proper foreign key constraints, and 9 advanced analytical queries. |
| ğŸ“ˆ **Statistics** | ANOVA confirms significant price differences across room types; MANOVA reveals multivariate effects on price + satisfaction + cleanliness. |

---

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.10+**
- **Git LFS** â€” required for large file downloads

### Installation

```bash
# 1. Install Git LFS (if not already installed)
git lfs install

# 2. Clone the repository (LFS files download automatically)
git clone https://github.com/Ahmed-Esso/airbnb-analytics.git
cd airbnb-analytics

# 3. Create and activate virtual environment
python -m venv venv
venv\Scripts\activate            # Windows
# source venv/bin/activate       # Linux / Mac

# 4. Install dependencies
pip install -r requirements.txt
```

### Run the Streamlit App

```bash
streamlit run app/app.py
```

The app will open at **http://localhost:8501** ğŸ‰

### Run the Scraper (Optional)

```bash
# Install Playwright browsers first
pip install playwright
playwright install chromium

# CLI scraper
python scraper/scraper_cli.py

# GUI scraper
python scraper/scraper_gui.py
```

### Run R Statistics (Optional)

```r
# In RStudio or R console, set the working directory to the repo root
setwd("path/to/airbnb-analytics")
source("r_statistics/stat.R")
```

---

## â˜ Streamlit Cloud Deployment

This project is **ready for one-click deployment** on [Streamlit Community Cloud](https://share.streamlit.io):

1. Go to [share.streamlit.io](https://share.streamlit.io) and sign in with GitHub
2. Click **"New app"**
3. Select the `airbnb-analytics` repository
4. Set **Main file path** to `app/app.py`
5. Click **Deploy** ğŸš€

> **Note:** Streamlit Cloud supports Git LFS and automatically detects `requirements.txt` at the repo root. No additional configuration needed.

---

## ğŸ“Š Dashboard Gallery

<table>
  <tr>
    <td><strong>Page 1 â€” Overview</strong></td>
    <td><strong>Page 2 â€” City Comparison</strong></td>
  </tr>
  <tr>
    <td><img src="dashboard/screenshots/page_1.jpg" alt="Dashboard Page 1" width="100%"></td>
    <td><img src="dashboard/screenshots/page_2.jpg" alt="Dashboard Page 2" width="100%"></td>
  </tr>
  <tr>
    <td><strong>Page 3 â€” Pricing Analysis</strong></td>
    <td><strong>Page 4 â€” Host & Amenity Insights</strong></td>
  </tr>
  <tr>
    <td><img src="dashboard/screenshots/page_3.jpg" alt="Dashboard Page 3" width="100%"></td>
    <td><img src="dashboard/screenshots/page_4.jpg" alt="Dashboard Page 4" width="100%"></td>
  </tr>
</table>

---

## ğŸ—ƒ Star Schema & Database

### Schema Diagram

![Star Schema Diagram](schema/schema_diagram.png)

The data warehouse (`Airbnb_DW`) uses a **star schema** design with:

| Table | Type | Key Columns |
|-------|------|-------------|
| `Fact_Listings` | Fact | `realSum`, `person_capacity`, `bedrooms`, `beds`, `cleanliness_rating`, `guest_satisfaction_overall`, `dist`, `metro_dist`, `attr_index`, `rest_index` |
| `Dim_Location` | Dimension | `city`, `country`, `latitude`, `longitude` |
| `Dim_Host` | Dimension | `host_is_superhost` |
| `Dim_Room_Type` | Dimension | `room_type`, `room_shared`, `room_private` |
| `Dim_Amenities` | Dimension | `wifi`, `kitchen`, `air_conditioning`, `parking`, `tv`, `heating` |
| `Dim_Day` | Dimension | `day_type`, `is_weekend`, `biz`, `multi` |

### SQL Server Setup (Optional)

1. Open `schema/star_schema.sql` in SQL Server Management Studio (SSMS)
2. Update the `BULK INSERT` path to your local `schema/final_raw_with_ids.csv`
3. Execute the script to create the `Airbnb_DW` database and populate all tables
4. Run `schema/analysis.sql` for the 9 advanced analytical queries

---

## ğŸ“œ License

This project is for **educational and portfolio purposes**.

---

## ğŸ‘¥ Team Members

| Name | GitHub |
|------|--------|
| **Ahmed Essam** | [@Ahmed-Esso](https://github.com/Ahmed-Esso) |
| **Mayar Hany** | [@Mayar-hany-2005](https://github.com/Mayar-hany-2005) |
| **Ziad Abdeen** | |
| **Seif Nour** | |

---

<div align="center">

**Built with â¤ï¸ by the Airbnb Analytics Team**

</div>
