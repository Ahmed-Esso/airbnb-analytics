{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6b923c",
   "metadata": {},
   "source": [
    "# Star Schema Data Processing Pipeline\n",
    "This notebook creates a star schema with dimension tables and a fact table for Airbnb data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a06d0",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "Import required libraries and load the source dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c8176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_14040\\2752770956.py:4: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"..\", \"app\", \"data\", \"airbnb_listings_clean.csv\"))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"..\", \"app\", \"data\", \"airbnb_listings_clean.csv\"))\n",
    "\n",
    "# Hash function to generate unique IDs from column values\n",
    "def hash_id(*cols):\n",
    "    key = \"_\".join([str(c) for c in cols])\n",
    "    return int(hashlib.md5(key.encode()).hexdigest()[:10], 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c5a33f",
   "metadata": {},
   "source": [
    "## 2. Create Dimension Tables\n",
    "Generate dimension tables with unique IDs using hash functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7623f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension Table 1: Location\n",
    "# Extract unique location combinations and generate location_id\n",
    "dim_location = df[['city','country','latitude','longitude']].drop_duplicates()\n",
    "\n",
    "dim_location['location_id'] = dim_location.apply(\n",
    "    lambda r: hash_id(r['city'], r['country'], r['latitude'], r['longitude']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f74278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension Table 2: Host\n",
    "# Extract unique host attributes and generate host_id\n",
    "dim_host = df[['host_is_superhost']].drop_duplicates()\n",
    "\n",
    "dim_host['host_id'] = dim_host.apply(\n",
    "    lambda r: hash_id(r['host_is_superhost']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33abb8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension Table 3: Room Type\n",
    "# Extract unique room type combinations and generate room_type_id\n",
    "dim_room = df[['room_type','room_shared','room_private']].drop_duplicates()\n",
    "\n",
    "dim_room['room_type_id'] = dim_room.apply(\n",
    "    lambda r: hash_id(r['room_type'], r['room_shared'], r['room_private']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension Table 4: Amenities\n",
    "# Extract unique amenity combinations and generate amenity_id\n",
    "amen_cols = ['wifi','kitchen','air_conditioning','parking','tv','heating']\n",
    "dim_amen = df[amen_cols].drop_duplicates()\n",
    "\n",
    "dim_amen['amenity_id'] = dim_amen.apply(\n",
    "    lambda r: hash_id(*r.values),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a3f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension Table 5: Day Type\n",
    "# Extract unique day type combinations and generate day_id\n",
    "day_cols = ['day_type','is_weekend','biz','multi']\n",
    "dim_day = df[day_cols].drop_duplicates()\n",
    "\n",
    "dim_day['day_id'] = dim_day.apply(\n",
    "    lambda r: hash_id(*r.values),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3079a4",
   "metadata": {},
   "source": [
    "## 3. Create Fact Table\n",
    "Merge all dimension IDs with the original data and create the fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge original data with all dimension tables to get foreign key IDs\n",
    "fact = df.merge(dim_location, on=['city','country','latitude','longitude'])\n",
    "fact = fact.merge(dim_host, on=['host_is_superhost'])\n",
    "fact = fact.merge(dim_room, on=['room_type','room_shared','room_private'])\n",
    "fact = fact.merge(dim_amen, on=amen_cols)\n",
    "fact = fact.merge(dim_day, on=day_cols)\n",
    "\n",
    "# Select only the relevant columns for the fact table (IDs + measures)\n",
    "fact_table = fact[['location_id','host_id','room_type_id','amenity_id','day_id',\n",
    "                   'realSum','person_capacity','bedrooms','beds',\n",
    "                   'cleanliness_rating','guest_satisfaction_overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14034d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the fact table to CSV\n",
    "fact_table.to_csv(\"fact_table_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8eb60d",
   "metadata": {},
   "source": [
    "## 4. Merge IDs Back to Original Dataset\n",
    "Combine the original data with the generated dimension IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f57fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_14040\\2932696193.py:1: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"..\", \"app\", \"data\", \"airbnb_listings_clean.csv\"))\n"
     ]
    }
   ],
   "source": [
    "# Reload the original dataset and fact table with IDs\n",
    "df = pd.read_csv(os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"..\", \"app\", \"data\", \"airbnb_listings_clean.csv\"))\n",
    "ids = pd.read_csv(\"fact_table_output.csv\")\n",
    "\n",
    "# Merge original data with IDs based on row index\n",
    "final = df.merge(ids, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d105cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['realSum_x', 'room_type', 'room_shared', 'room_private',\n",
      "       'person_capacity_x', 'host_is_superhost', 'multi', 'biz',\n",
      "       'cleanliness_rating_x', 'guest_satisfaction_overall_x', 'bedrooms_x',\n",
      "       'dist', 'metro_dist', 'attr_index', 'attr_index_norm', 'rest_index',\n",
      "       'rest_index_norm', 'longitude', 'latitude', 'city', 'country',\n",
      "       'day_type', 'is_weekend', 'beds_x', 'wifi', 'kitchen',\n",
      "       'air_conditioning', 'parking', 'tv', 'heating', 'host_location',\n",
      "       'host_listings_count', 'location_id', 'host_id', 'room_type_id',\n",
      "       'amenity_id', 'day_id', 'realSum_y', 'person_capacity_y', 'bedrooms_y',\n",
      "       'beds_y', 'cleanliness_rating_y', 'guest_satisfaction_overall_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the column names to identify duplicates\n",
    "print(final.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19ecd0",
   "metadata": {},
   "source": [
    "## 5. Clean Up Duplicate Columns\n",
    "Remove duplicate columns created during the merge and rename properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d105cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate columns (suffixed with _y from the merge)\n",
    "final = final.drop(columns=[\n",
    "    'realSum_y',\n",
    "    'person_capacity_y',\n",
    "    'bedrooms_y',\n",
    "    'beds_y',\n",
    "    'cleanliness_rating_y',\n",
    "    'guest_satisfaction_overall_y'\n",
    "])\n",
    "\n",
    "# Rename columns with _x suffix back to their original names\n",
    "final = final.rename(columns={\n",
    "    'realSum_x': 'realSum',\n",
    "    'person_capacity_x': 'person_capacity',\n",
    "    'bedrooms_x': 'bedrooms',\n",
    "    'beds_x': 'beds',\n",
    "    'cleanliness_rating_x': 'cleanliness_rating',\n",
    "    'guest_satisfaction_overall_x': 'guest_satisfaction_overall'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7644e8c",
   "metadata": {},
   "source": [
    "## 6. Export Final Dataset\n",
    "Save the cleaned dataset with all dimension IDs included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final dataset with dimension IDs to CSV\n",
    "final.to_csv(\"final_raw_with_ids.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
